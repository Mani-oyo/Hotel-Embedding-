{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcf02482",
   "metadata": {},
   "source": [
    "### Developer: Mani kanta\n",
    "\n",
    "### Aim: Embedding generation using Skip Gram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58643309",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd7d369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import collections\n",
    "import math\n",
    "import random\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as Func\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import time\n",
    "\n",
    "from s3fs.core import S3FileSystem\n",
    "import io\n",
    "s3 = S3FileSystem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f8fb097",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data  = np.load(s3.open('prod-search-ranking-ml/data/Umang/pos_sample_3.npy'),allow_pickle=True)\n",
    "within_city = np.load(s3.open('prod-search-ranking-ml/data/Umang/neg_sample_city_3.npy'),allow_pickle=True)\n",
    "within_country = np.load(s3.open('prod-search-ranking-ml/data/Umang/neg_sample_country_3.npy'),allow_pickle=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5857a0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1966945"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2168c02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1966945"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(within_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54d740f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1966945"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(within_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b45baa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81417, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hotel=pd.read_csv(\"Hotel.csv\")\n",
    "hotel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e80cb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>city_name</th>\n",
       "      <th>country_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>94319</td>\n",
       "      <td>678.0</td>\n",
       "      <td>Nha-Trang</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13195</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>89191</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>86999</td>\n",
       "      <td>421.0</td>\n",
       "      <td>Karimnagar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>87204</td>\n",
       "      <td>677.0</td>\n",
       "      <td>Krabi</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81412</th>\n",
       "      <td>81412</td>\n",
       "      <td>62801</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81413</th>\n",
       "      <td>81413</td>\n",
       "      <td>97059</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81414</th>\n",
       "      <td>81414</td>\n",
       "      <td>110181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81415</th>\n",
       "      <td>81415</td>\n",
       "      <td>5298</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81416</th>\n",
       "      <td>81416</td>\n",
       "      <td>59541</td>\n",
       "      <td>699.0</td>\n",
       "      <td>Kasargod</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81417 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  hotel_id  city_id   city_name  country_id\n",
       "0               0     94319    678.0   Nha-Trang         217\n",
       "1               1     13195      4.0   Bangalore           1\n",
       "2               2     89191      4.0   Bangalore           1\n",
       "3               3     86999    421.0  Karimnagar           1\n",
       "4               4     87204    677.0       Krabi           8\n",
       "...           ...       ...      ...         ...         ...\n",
       "81412       81412     62801      1.0     Gurgaon           1\n",
       "81413       81413     97059     14.0     Kolkata           1\n",
       "81414       81414    110181      1.0     Gurgaon           1\n",
       "81415       81415      5298      5.0      Mumbai           1\n",
       "81416       81416     59541    699.0    Kasargod           1\n",
       "\n",
       "[81417 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0615b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accb5d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class skipgram(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(skipgram, self).__init__()\n",
    "        self.u_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True)   \n",
    "        self.v_embeddings = nn.Embedding(vocab_size, embedding_dim, sparse=True) \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.init_emb()\n",
    "    \n",
    "    def init_emb(self):\n",
    "        initrange = 0.5 / self.embedding_dim\n",
    "        self.u_embeddings.weight.data.uniform_(-initrange, initrange)\n",
    "        self.v_embeddings.weight.data.uniform_(-0, 0)\n",
    "    \n",
    "    def forward(self, u_pos, v_pos, v_neg_city, v_neg_country):\n",
    "\n",
    "        embed_u = self.u_embeddings(u_pos)\n",
    "        embed_v = self.v_embeddings(v_pos)\n",
    "        \n",
    "        embed_u = embed_u.unsqueeze(0)\n",
    "\n",
    "        score  = torch.mul(embed_u, embed_v)\n",
    "        score = torch.sum(score, dim=1)\n",
    "        log_target = F.logsigmoid(score).squeeze()\n",
    "\n",
    "        neg_embed_v_city = self.v_embeddings(v_neg_city)\n",
    "        neg_embed_v_country = self.v_embeddings(v_neg_country)\n",
    "\n",
    "        neg_score_city = torch.mul(neg_embed_v_city, embed_u)\n",
    "        neg_score_city = torch.sum(neg_score_city, dim=1)\n",
    "        sum_log_neg_score_city = F.logsigmoid(-1*neg_score_city).squeeze()\n",
    "        \n",
    "        neg_score_country = torch.mul(neg_embed_v_country, embed_u)\n",
    "        neg_score_country = torch.sum(neg_score_country, dim=1)\n",
    "        sum_log_neg_score_country = F.logsigmoid(-1*neg_score_country).squeeze()\n",
    "\n",
    "        loss = log_target.sum() + sum_log_neg_score_city.sum() + sum_log_neg_score_country.sum()\n",
    "\n",
    "        return -1*loss\n",
    "    \n",
    "    def input_embeddings(self):\n",
    "        return self.u_embeddings.weight.data.cpu().numpy()\n",
    "   \n",
    "    def save_embedding(self, file_name, id2word):\n",
    "        embeds = self.u_embeddings.weight.data\n",
    "        fo = open(file_name, 'w')\n",
    "        for idx in range(len(embeds)):\n",
    "            word = id2word(idx)\n",
    "            embed = ' '.join(embeds[idx])\n",
    "            fo.write(word+' '+embed+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabc1cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 368130/1966945 [08:06<35:14, 756.03it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0bd6b676c134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mcenter_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mpositive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mneg_within_city\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwithin_city\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mneg_within_country\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwithin_country\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = skipgram(81417, 200).to(device)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.2)\n",
    "\n",
    "for epoch in range(10):\n",
    "    start = time.time()     \n",
    "    total_loss = 0\n",
    "    batch_num = 0\n",
    "    batch_new = 0\n",
    "\n",
    "    for i in tqdm(range(len(train_data))):\n",
    "        center_id = torch.tensor(train_data[i][0]).to(device)\n",
    "        positive = torch.tensor(train_data[i][1]).to(device)\n",
    "        neg_within_city = torch.tensor(within_city[i]).to(device)\n",
    "        neg_within_country = torch.tensor(within_country[i]).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = model(center_id, positive, neg_within_city, neg_within_country)\n",
    "        \n",
    "        total_loss += loss\n",
    "#         print(loss)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "            \n",
    "        batch_num = batch_num + 1 \n",
    "    print(\"epoch done\")\n",
    "    print(\"Epoch Loss \", epoch ,\" \", total_loss)\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f4c9370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Tesla T4\n",
      "Memory Usage:\n",
      "Allocated: 0.1 GB\n",
      "Cached:    0.1 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7f9440c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.064330460110516"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03ab3240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1644914256248737"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "167115/143509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64006120",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.01"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
